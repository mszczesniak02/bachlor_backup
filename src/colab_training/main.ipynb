{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "from google.colab import drive\n",
        "import glob\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "from tqdm.auto import tqdm\n",
        "def make_dirs():\n",
        "    # make dirs for models & logs\n",
        "    dirs = [\n",
        "        \"/content/models\",\n",
        "\n",
        "        \"/content/models/segmentation\",\n",
        "        \"/content/models/classification\",\n",
        "        \"/content/models/autoencoder\",\n",
        "\n",
        "        \"/content/models/segmentation/unet\",\n",
        "        \"/content/models/segmentation/segformer\",\n",
        "        \"/content/models/classification/efficienet\",\n",
        "        \"/content/models/classification/convnext\",\n",
        "\n",
        "        \"/content/models_log\",\n",
        "\n",
        "        \"/content/models_log/segmentation\",\n",
        "        \"/content/models_log/segmentation/unet\",\n",
        "        \"/content/models_log/segmentation/segformer\",\n",
        "\n",
        "        \"/content/models_log/classification\",\n",
        "        \"/content/models_log/classification/efficienet\",\n",
        "        \"/content/models_log/classification/convnext\",\n",
        "        \"/content/models_log/autoencoder\",\n",
        "    ]\n",
        "    for dir in dirs:\n",
        "        os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "def mount_drive():\n",
        "\n",
        "    drive.mount('/content/drive')\n",
        "    source = '/content/drive/MyDrive/datasets/multi'  # Na Drive\n",
        "    destination = '/content/datasets/multi'            # Link lokalny\n",
        "\n",
        "    os.makedirs('/content/datasets', exist_ok=True)\n",
        "\n",
        "    if os.path.exists(destination):\n",
        "        if os.path.islink(destination):\n",
        "            os.unlink(destination)\n",
        "        else:\n",
        "            shutil.rmtree(destination)\n",
        "\n",
        "    # os.symlink(source, destination)\n",
        "    print(f\"Copying dataset from {source} to {destination}...\")\n",
        "\n",
        "    # Count files for progress bar\n",
        "    total_files = sum([len(files) for r, d, files in os.walk(source)])\n",
        "\n",
        "    with tqdm(total=total_files, desc=\"Copying\", unit=\"file\") as pbar:\n",
        "        def copy_func(src, dst):\n",
        "            shutil.copy2(src, dst)\n",
        "            pbar.update(1)\n",
        "\n",
        "        shutil.copytree(source, destination, copy_function=copy_func)\n",
        "\n",
        "    print(f\"Dataset copied!\")\n",
        "    print(f\"  {destination} <- {source}\")\n",
        "\n",
        "def set_colab(path: str, on_colab: bool):\n",
        "    dir = Path(path)\n",
        "    result = list(dir.rglob(\"hparams.[pP][yY]\"))\n",
        "    for r in result:\n",
        "        with open(r, \"r+\") as f:\n",
        "            pos = f.tell()\n",
        "            line = f.readline()\n",
        "            if on_colab:\n",
        "                if line == \"ON_COLAB = False\\n\":\n",
        "                    f.seek(pos)\n",
        "                    f.write(\"ON_COLAB = True\\n\")\n",
        "            else:\n",
        "                if line == \"ON_COLAB = True\\n\":\n",
        "                    f.seek(pos)\n",
        "                    f.write(\"ON_COLAB = False\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "2M7KNO36nYXa"
      },
      "id": "2M7KNO36nYXa",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1e8iUa45OsATWGrFJOVfE3x9-YZrWTQXG -O dataset.tar.gz\n",
        "!mkdir /content/datasets\n",
        "!tar -I pigz -xf /content/dataset.tar.gz -C /content/datasets/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lAy4qrunpII",
        "outputId": "109585b5-e7d7-4309-c290-a98598eccc4c"
      },
      "id": "5lAy4qrunpII",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1e8iUa45OsATWGrFJOVfE3x9-YZrWTQXG\n",
            "From (redirected): https://drive.google.com/uc?id=1e8iUa45OsATWGrFJOVfE3x9-YZrWTQXG&confirm=t&uuid=4bce59aa-da15-4e6f-a37b-506b9b7779f4\n",
            "To: /content/dataset.tar.gz\n",
            "100% 1.86G/1.86G [00:10<00:00, 183MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8ceb493c",
      "metadata": {
        "id": "8ceb493c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f2a7d6e-cd57-4bd5-e383-658e95d2dc64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/154.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/983.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hON_COLAB = True\n",
            "ON_COLAB = True\n",
            "ON_COLAB = True\n",
            "cat: bachlor_backup/src/dim_translator/hparams.py: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!pip install -q segmentation-models-pytorch torchmetrics\n",
        "!pip install -q torchmetrics\n",
        "!git clone -q https://github.com/mszczesniak02/bachlor_backup.git\n",
        "make_dirs()\n",
        "set_colab(\"/content/bachlor_backup/src\", True)\n",
        "\n",
        "!cat bachlor_backup/src/segmentation/common/hparams.py | head -1\n",
        "!cat bachlor_backup/src/classification/common/hparams.py | head -1\n",
        "!cat bachlor_backup/src/autoencoder/hparams.py | head -1\n",
        "!cat bachlor_backup/src/dim_translator/hparams.py | head -1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rd bachlor_backup/\n",
        "!git clone -q https://github.com/mszczesniak02/bachlor_backup.git\n",
        "make_dirs()\n",
        "set_colab(\"/content/bachlor_backup/src\", True)\n",
        "\n",
        "!cat bachlor_backup/src/segmentation/common/hparams.py | head -1\n",
        "!cat bachlor_backup/src/classification/common/hparams.py | head -1\n",
        "!cat bachlor_backup/src/autoencoder/hparams.py | head -1\n",
        "!cat bachlor_backup/src/dim_translator/hparams.py | head -1\n"
      ],
      "metadata": {
        "id": "o608R36nmc2q"
      },
      "id": "o608R36nmc2q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd bachlor_backup/src/segmentation/unet/ && python train.py"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-WcQQDSWU-DO"
      },
      "id": "-WcQQDSWU-DO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "original_sys_path = sys.path.copy()\n",
        "\n",
        "# sys.path.append('/content/bachlor_backup/src/autoencoder')\n",
        "# import train as autoencoder_train\n",
        "\n",
        "sys.path.append('/content/bachlor_backup/src/segmentation/unet/')\n",
        "import train as unet_train\n",
        "\n",
        "# sys.path.append('/content/bachlor_backup/src/segmentation/segformer/')\n",
        "# import train as segformer_train\n",
        "\n",
        "# sys.path.append('/content/bachlor_backup/src/classification/convnext')\n",
        "# import train as convnext_train\n",
        "\n",
        "# sys.path.append('/content/bachlor_backup/src/classification/efficienet')\n",
        "# import train as efficienet_train\n"
      ],
      "metadata": {
        "id": "1iST6XJ7khyT"
      },
      "id": "1iST6XJ7khyT",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet_train.main()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-SpXut3SaM64"
      },
      "id": "-SpXut3SaM64",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZlmPIjWNCHdo"
      },
      "id": "ZlmPIjWNCHdo",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}