{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "from google.colab import drive\n",
        "import glob\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "from tqdm.auto import tqdm\n",
        "def make_dirs():\n",
        "    # make dirs for models & logs\n",
        "    dirs = [\n",
        "        \"/content/models\",\n",
        "\n",
        "        \"/content/models/segmentation\",\n",
        "        \"/content/models/classification\",\n",
        "        \"/content/models/autoencoder\",\n",
        "\n",
        "        \"/content/models/segmentation/unet\",\n",
        "        \"/content/models/segmentation/segformer\",\n",
        "        \"/content/models/classification/efficienet\",\n",
        "        \"/content/models/classification/convnext\",\n",
        "\n",
        "        \"/content/models_log\",\n",
        "\n",
        "        \"/content/models_log/segmentation\",\n",
        "        \"/content/models_log/segmentation/unet\",\n",
        "        \"/content/models_log/segmentation/segformer\",\n",
        "\n",
        "        \"/content/models_log/classification\",\n",
        "        \"/content/models_log/classification/efficienet\",\n",
        "        \"/content/models_log/classification/convnext\",\n",
        "        \"/content/models_log/autoencoder\",\n",
        "    ]\n",
        "    for dir in dirs:\n",
        "        os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "def mount_drive():\n",
        "\n",
        "    drive.mount('/content/drive')\n",
        "    source = '/content/drive/MyDrive/datasets/multi'  # Na Drive\n",
        "    destination = '/content/datasets/multi'            # Link lokalny\n",
        "\n",
        "    os.makedirs('/content/datasets', exist_ok=True)\n",
        "\n",
        "    if os.path.exists(destination):\n",
        "        if os.path.islink(destination):\n",
        "            os.unlink(destination)\n",
        "        else:\n",
        "            shutil.rmtree(destination)\n",
        "\n",
        "    # os.symlink(source, destination)\n",
        "    print(f\"Copying dataset from {source} to {destination}...\")\n",
        "\n",
        "    # Count files for progress bar\n",
        "    total_files = sum([len(files) for r, d, files in os.walk(source)])\n",
        "\n",
        "    with tqdm(total=total_files, desc=\"Copying\", unit=\"file\") as pbar:\n",
        "        def copy_func(src, dst):\n",
        "            shutil.copy2(src, dst)\n",
        "            pbar.update(1)\n",
        "\n",
        "        shutil.copytree(source, destination, copy_function=copy_func)\n",
        "\n",
        "    print(f\"Dataset copied!\")\n",
        "    print(f\"  {destination} <- {source}\")\n",
        "\n",
        "def set_colab(path: str, on_colab: bool):\n",
        "    dir = Path(path)\n",
        "    result = list(dir.rglob(\"hparams.[pP][yY]\"))\n",
        "    for r in result:\n",
        "        with open(r, \"r+\") as f:\n",
        "            pos = f.tell()\n",
        "            line = f.readline()\n",
        "            if on_colab:\n",
        "                if line == \"ON_COLAB = False\\n\":\n",
        "                    f.seek(pos)\n",
        "                    f.write(\"ON_COLAB = True\\n\")\n",
        "            else:\n",
        "                if line == \"ON_COLAB = True\\n\":\n",
        "                    f.seek(pos)\n",
        "                    f.write(\"ON_COLAB = False\\n\")\n",
        "\n",
        "def set_hparams(unet_epochs=15, segformer_epochs=15):\n",
        "    \"\"\"\n",
        "    Zmienia wartości hiperparametrów w pliku hparams.py\n",
        "\n",
        "    Args:\n",
        "        unet_epochs (int, optional): Liczba epok dla U-Net. Default: 15\n",
        "        segformer_epochs (int, optional): Liczba epok dla SegFormer. Default: 15\n",
        "\n",
        "    Returns:\n",
        "        bool: True jeśli sukces, False jeśli błąd\n",
        "    \"\"\"\n",
        "    import re\n",
        "\n",
        "    hparams_file = \"/content/bachlor_backup/src/segmentation/common/hparams.py\"\n",
        "\n",
        "    try:\n",
        "        # Wczytaj zawartość pliku\n",
        "        with open(hparams_file, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "\n",
        "        # Zmień UNET_EPOCHS\n",
        "        content = re.sub(\n",
        "            r'UNET_EPOCHS = \\d+',\n",
        "            f'UNET_EPOCHS = {unet_epochs}',\n",
        "            content\n",
        "        )\n",
        "\n",
        "        # Zmień SEGFORMER_EPOCHS\n",
        "        content = re.sub(\n",
        "            r'SEGFORMER_EPOCHS = \\d+',\n",
        "            f'SEGFORMER_EPOCHS = {segformer_epochs}',\n",
        "            content\n",
        "        )\n",
        "\n",
        "        # Zapisz zmieniony plik\n",
        "        with open(hparams_file, 'w', encoding='utf-8') as f:\n",
        "            f.write(content)\n",
        "\n",
        "        print(f\"✓ Ustawiono parametry:\")\n",
        "        print(f\"  - UNET_EPOCHS = {unet_epochs}\")\n",
        "        print(f\"  - SEGFORMER_EPOCHS = {segformer_epochs}\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Błąd: {e}\")\n",
        "        return False\n",
        "def set_resume_checkpoint(checkpoint_path=None):\n",
        "    \"\"\"\n",
        "    Zmienia wartość RESUME_CHECKPOINT w pliku train.py\n",
        "\n",
        "    Args:\n",
        "        checkpoint_path (str, optional): Ścieżka do checkpointa.\n",
        "                                        Jeśli None, ustawia RESUME_CHECKPOINT = None\n",
        "\n",
        "    Returns:\n",
        "        bool: True jeśli sukces, False jeśli błąd\n",
        "    \"\"\"\n",
        "    import re\n",
        "\n",
        "    train_file = \"/content/bachlor_backup/src/segmentation/unet/train.py\"\n",
        "\n",
        "    try:\n",
        "        # Wczytaj zawartość pliku\n",
        "        with open(train_file, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "\n",
        "        # Przygotuj nową wartość\n",
        "        if checkpoint_path is None:\n",
        "            new_value = \"RESUME_CHECKPOINT = None\"\n",
        "        else:\n",
        "            # Escapuj backslashe dla Windows paths\n",
        "            escaped_path = checkpoint_path.replace('\\\\', '\\\\\\\\')\n",
        "            new_value = f'RESUME_CHECKPOINT = \"{escaped_path}\"'\n",
        "\n",
        "        # Zamień linie z RESUME_CHECKPOINT\n",
        "        pattern = r'RESUME_CHECKPOINT = .*'\n",
        "        content = re.sub(pattern, new_value, content)\n",
        "\n",
        "        # Zapisz zmieniony plik\n",
        "        with open(train_file, 'w', encoding='utf-8') as f:\n",
        "            f.write(content)\n",
        "\n",
        "        print(f\"✓ Ustawiono: {new_value}\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Błąd: {e}\")\n",
        "        return False"
      ],
      "metadata": {
        "id": "2M7KNO36nYXa"
      },
      "id": "2M7KNO36nYXa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_hparams(22,15)\n",
        "set_resume_checkpoint(\"/content/model_unet_0.5704742482859014.pth\")"
      ],
      "metadata": {
        "id": "miH-0fBoZ-mW"
      },
      "id": "miH-0fBoZ-mW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get -qq install zstd\n",
        "!gdown --id 1ZCY_ewakkoxohu4qqk4kHHgBCqi0urIn -O dataset_segmentation.tar.zst\n",
        "!mkdir /content/datasets\n",
        "!tar -xf /content/dataset_segmentation.tar.zst -C /content/datasets/\n",
        "!mv /content/datasets/dataset_segmentation/ /content/datasets/multi/\n",
        "\n",
        "!gdown --id 1I7gjpPDWnuz5AmsiMcxEvoFQW1-ZkW9i -O DeepCrack.zip\n",
        "!mkdir /content/datasets/DeepCrack/ && cd /content/datasets/DeepCrack/ && unzip /content/DeepCrack.zip"
      ],
      "metadata": {
        "id": "5lAy4qrunpII"
      },
      "id": "5lAy4qrunpII",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dEowngL9-RHI"
      },
      "id": "dEowngL9-RHI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q segmentation-models-pytorch torchmetrics\n",
        "!pip install -q torchmetrics\n",
        "!git clone -q https://github.com/mszczesniak02/bachlor_backup.git\n",
        "make_dirs()\n",
        "set_colab(\"/content/bachlor_backup/src\", True)\n",
        "\n",
        "!cat bachlor_backup/src/segmentation/common/hparams.py | head -1\n",
        "!cat bachlor_backup/src/classification/common/hparams.py | head -1\n",
        "!cat bachlor_backup/src/autoencoder/hparams.py | head -1\n",
        "!cat bachlor_backup/src/dim_translator/hparams.py | head -1"
      ],
      "metadata": {
        "id": "TPyqSzWH6E02"
      },
      "id": "TPyqSzWH6E02",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rd bachlor_backup/\n",
        "!git clone -q https://github.com/mszczesniak02/bachlor_backup.git\n",
        "make_dirs()\n",
        "set_colab(\"/content/bachlor_backup/src\", True)\n",
        "\n",
        "!cat bachlor_backup/src/segmentation/common/hparams.py | head -1\n",
        "!cat bachlor_backup/src/classification/common/hparams.py | head -1\n",
        "!cat bachlor_backup/src/autoencoder/hparams.py | head -1\n",
        "!cat bachlor_backup/src/dim_translator/hparams.py | head -1\n"
      ],
      "metadata": {
        "id": "o608R36nmc2q"
      },
      "id": "o608R36nmc2q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd bachlor_backup/src/segmentation/unet/ && python train.py"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-WcQQDSWU-DO"
      },
      "id": "-WcQQDSWU-DO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd bachlor_backup/src/segmentation/yolo_8_seg/datasets_prepair/ && python prepare.py"
      ],
      "metadata": {
        "id": "Zc_5ysu6_Ie5"
      },
      "id": "Zc_5ysu6_Ie5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "original_sys_path = sys.path.copy()\n",
        "\n",
        "# sys.path.append('/content/bachlor_backup/src/autoencoder')\n",
        "# import train as autoencoder_train\n",
        "\n",
        "sys.path.append('/content/bachlor_backup/src/segmentation/unet/')\n",
        "import train as unet_train\n",
        "# sys.path.append('/content/bachlor_backup/src/segmentation/segformer/')\n",
        "# import train as segformer_train\n",
        "\n",
        "# sys.path.append('/content/bachlor_backup/src/classification/convnext')\n",
        "# import train as convnext_train\n",
        "\n",
        "# sys.path.append('/content/bachlor_backup/src/classification/efficienet')\n",
        "# import train as efficienet_train\n",
        "\n",
        "sys.path.append('/content/bachlor_backup/src/segmentation/yolo_8_seg/')\n",
        "import train as yolo_train\n"
      ],
      "metadata": {
        "id": "zeC4Tv5b60yi"
      },
      "id": "zeC4Tv5b60yi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yolo_train.main()"
      ],
      "metadata": {
        "id": "-SpXut3SaM64"
      },
      "id": "-SpXut3SaM64",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mMeZmCGYH0VX"
      },
      "id": "mMeZmCGYH0VX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "dd8u_mo_H7Iy"
      },
      "id": "dd8u_mo_H7Iy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python bachlor_backup/src/segmentation/yolo_8_seg/train.py"
      ],
      "metadata": {
        "id": "-xvYxDL4fv7s"
      },
      "id": "-xvYxDL4fv7s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZlmPIjWNCHdo"
      },
      "id": "ZlmPIjWNCHdo",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}