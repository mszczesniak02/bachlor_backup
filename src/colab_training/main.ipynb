{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "from google.colab import drive\n",
        "import glob\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "from tqdm.auto import tqdm\n",
        "def make_dirs():\n",
        "    # make dirs for models & logs\n",
        "    dirs = [\n",
        "        \"/content/models\",\n",
        "\n",
        "        \"/content/models/segmentation\",\n",
        "        \"/content/models/classification\",\n",
        "        \"/content/models/autoencoder\",\n",
        "\n",
        "        \"/content/models/segmentation/unet\",\n",
        "        \"/content/models/segmentation/segformer\",\n",
        "        \"/content/models/classification/efficienet\",\n",
        "        \"/content/models/classification/convnext\",\n",
        "\n",
        "        \"/content/models_log\",\n",
        "\n",
        "        \"/content/models_log/segmentation\",\n",
        "        \"/content/models_log/segmentation/unet\",\n",
        "        \"/content/models_log/segmentation/segformer\",\n",
        "\n",
        "        \"/content/models_log/classification\",\n",
        "        \"/content/models_log/classification/efficienet\",\n",
        "        \"/content/models_log/classification/convnext\",\n",
        "        \"/content/models_log/autoencoder\",\n",
        "    ]\n",
        "    for dir in dirs:\n",
        "        os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "def mount_drive():\n",
        "\n",
        "    drive.mount('/content/drive')\n",
        "    source = '/content/drive/MyDrive/datasets/multi'  # Na Drive\n",
        "    destination = '/content/datasets/multi'            # Link lokalny\n",
        "\n",
        "    os.makedirs('/content/datasets', exist_ok=True)\n",
        "\n",
        "    if os.path.exists(destination):\n",
        "        if os.path.islink(destination):\n",
        "            os.unlink(destination)\n",
        "        else:\n",
        "            shutil.rmtree(destination)\n",
        "\n",
        "    # os.symlink(source, destination)\n",
        "    print(f\"Copying dataset from {source} to {destination}...\")\n",
        "\n",
        "    # Count files for progress bar\n",
        "    total_files = sum([len(files) for r, d, files in os.walk(source)])\n",
        "\n",
        "    with tqdm(total=total_files, desc=\"Copying\", unit=\"file\") as pbar:\n",
        "        def copy_func(src, dst):\n",
        "            shutil.copy2(src, dst)\n",
        "            pbar.update(1)\n",
        "\n",
        "        shutil.copytree(source, destination, copy_function=copy_func)\n",
        "\n",
        "    print(f\"Dataset copied!\")\n",
        "    print(f\"  {destination} <- {source}\")\n",
        "\n",
        "def set_colab(path: str, on_colab: bool):\n",
        "    dir = Path(path)\n",
        "    result = list(dir.rglob(\"hparams.[pP][yY]\"))\n",
        "    for r in result:\n",
        "        with open(r, \"r+\") as f:\n",
        "            pos = f.tell()\n",
        "            line = f.readline()\n",
        "            if on_colab:\n",
        "                if line == \"ON_COLAB = False\\n\":\n",
        "                    f.seek(pos)\n",
        "                    f.write(\"ON_COLAB = True\\n\")\n",
        "            else:\n",
        "                if line == \"ON_COLAB = True\\n\":\n",
        "                    f.seek(pos)\n",
        "                    f.write(\"ON_COLAB = False\\n\")\n",
        "\n",
        "def set_hparams(unet_epochs=15, segformer_epochs=15):\n",
        "    \"\"\"\n",
        "    Zmienia wartości hiperparametrów w pliku hparams.py\n",
        "\n",
        "    Args:\n",
        "        unet_epochs (int, optional): Liczba epok dla U-Net. Default: 15\n",
        "        segformer_epochs (int, optional): Liczba epok dla SegFormer. Default: 15\n",
        "\n",
        "    Returns:\n",
        "        bool: True jeśli sukces, False jeśli błąd\n",
        "    \"\"\"\n",
        "    import re\n",
        "\n",
        "    hparams_file = \"/home/krzeslaav/Projects/bachlor/src/segmentation/common/hparams.py\"\n",
        "\n",
        "    try:\n",
        "        # Wczytaj zawartość pliku\n",
        "        with open(hparams_file, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "\n",
        "        # Zmień UNET_EPOCHS\n",
        "        content = re.sub(\n",
        "            r'UNET_EPOCHS = \\d+',\n",
        "            f'UNET_EPOCHS = {unet_epochs}',\n",
        "            content\n",
        "        )\n",
        "\n",
        "        # Zmień SEGFORMER_EPOCHS\n",
        "        content = re.sub(\n",
        "            r'SEGFORMER_EPOCHS = \\d+',\n",
        "            f'SEGFORMER_EPOCHS = {segformer_epochs}',\n",
        "            content\n",
        "        )\n",
        "\n",
        "        # Zapisz zmieniony plik\n",
        "        with open(hparams_file, 'w', encoding='utf-8') as f:\n",
        "            f.write(content)\n",
        "\n",
        "        print(f\"✓ Ustawiono parametry:\")\n",
        "        print(f\"  - UNET_EPOCHS = {unet_epochs}\")\n",
        "        print(f\"  - SEGFORMER_EPOCHS = {segformer_epochs}\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Błąd: {e}\")\n",
        "        return False\n",
        "def set_resume_checkpoint(checkpoint_path=None):\n",
        "    \"\"\"\n",
        "    Zmienia wartość RESUME_CHECKPOINT w pliku train.py\n",
        "\n",
        "    Args:\n",
        "        checkpoint_path (str, optional): Ścieżka do checkpointa.\n",
        "                                        Jeśli None, ustawia RESUME_CHECKPOINT = None\n",
        "\n",
        "    Returns:\n",
        "        bool: True jeśli sukces, False jeśli błąd\n",
        "    \"\"\"\n",
        "    import re\n",
        "\n",
        "    train_file = \"/home/krzeslaav/Projects/bachlor/src/segmentation/unet/train.py\"\n",
        "\n",
        "    try:\n",
        "        # Wczytaj zawartość pliku\n",
        "        with open(train_file, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "\n",
        "        # Przygotuj nową wartość\n",
        "        if checkpoint_path is None:\n",
        "            new_value = \"RESUME_CHECKPOINT = None\"\n",
        "        else:\n",
        "            # Escapuj backslashe dla Windows paths\n",
        "            escaped_path = checkpoint_path.replace('\\\\', '\\\\\\\\')\n",
        "            new_value = f'RESUME_CHECKPOINT = \"{escaped_path}\"'\n",
        "\n",
        "        # Zamień linie z RESUME_CHECKPOINT\n",
        "        pattern = r'RESUME_CHECKPOINT = .*'\n",
        "        content = re.sub(pattern, new_value, content)\n",
        "\n",
        "        # Zapisz zmieniony plik\n",
        "        with open(train_file, 'w', encoding='utf-8') as f:\n",
        "            f.write(content)\n",
        "\n",
        "        print(f\"✓ Ustawiono: {new_value}\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Błąd: {e}\")\n",
        "        return False"
      ],
      "metadata": {
        "id": "2M7KNO36nYXa"
      },
      "id": "2M7KNO36nYXa",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get -qq install zstd\n",
        "!gdown --id 1ZCY_ewakkoxohu4qqk4kHHgBCqi0urIn -O dataset_segmentation.tar.zst\n",
        "!mkdir /content/datasets\n",
        "!tar -xf /content/dataset_segmentation.tar.zst -C /content/datasets/\n",
        "!mv /content/datasets/dataset_segmentation/ /content/datasets/multi/\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lAy4qrunpII",
        "outputId": "0898b15b-71e2-46b8-dd3a-00a1f4964345"
      },
      "id": "5lAy4qrunpII",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package zstd.\n",
            "(Reading database ... 121689 files and directories currently installed.)\n",
            "Preparing to unpack .../zstd_1.4.8+dfsg-3build1_amd64.deb ...\n",
            "Unpacking zstd (1.4.8+dfsg-3build1) ...\n",
            "Setting up zstd (1.4.8+dfsg-3build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1ZCY_ewakkoxohu4qqk4kHHgBCqi0urIn\n",
            "From (redirected): https://drive.google.com/uc?id=1ZCY_ewakkoxohu4qqk4kHHgBCqi0urIn&confirm=t&uuid=27cb8927-657f-4b21-884b-a0ec65b1f7e0\n",
            "To: /content/dataset_segmentation.tar.zst\n",
            "100% 1.68G/1.68G [00:36<00:00, 45.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q segmentation-models-pytorch torchmetrics\n",
        "!pip install -q torchmetrics\n",
        "!git clone -q https://github.com/mszczesniak02/bachlor_backup.git\n",
        "make_dirs()\n",
        "set_colab(\"/content/bachlor_backup/src\", True)\n",
        "\n",
        "!cat bachlor_backup/src/segmentation/common/hparams.py | head -1\n",
        "!cat bachlor_backup/src/classification/common/hparams.py | head -1\n",
        "!cat bachlor_backup/src/autoencoder/hparams.py | head -1\n",
        "!cat bachlor_backup/src/dim_translator/hparams.py | head -1"
      ],
      "metadata": {
        "id": "TPyqSzWH6E02",
        "outputId": "c9024310-f098-4a4f-b24a-8da37eba7dd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "TPyqSzWH6E02",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/154.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/983.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hON_COLAB = True\n",
            "ON_COLAB = True\n",
            "ON_COLAB = True\n",
            "cat: bachlor_backup/src/dim_translator/hparams.py: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rd bachlor_backup/\n",
        "!git clone -q https://github.com/mszczesniak02/bachlor_backup.git\n",
        "make_dirs()\n",
        "set_colab(\"/content/bachlor_backup/src\", True)\n",
        "\n",
        "!cat bachlor_backup/src/segmentation/common/hparams.py | head -1\n",
        "!cat bachlor_backup/src/classification/common/hparams.py | head -1\n",
        "!cat bachlor_backup/src/autoencoder/hparams.py | head -1\n",
        "!cat bachlor_backup/src/dim_translator/hparams.py | head -1\n"
      ],
      "metadata": {
        "id": "o608R36nmc2q",
        "outputId": "dbba1252-5e9f-421b-f233-dc214360a6b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "o608R36nmc2q",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ON_COLAB = True\n",
            "ON_COLAB = True\n",
            "ON_COLAB = True\n",
            "cat: bachlor_backup/src/dim_translator/hparams.py: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd bachlor_backup/src/segmentation/unet/ && python train.py"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-WcQQDSWU-DO"
      },
      "id": "-WcQQDSWU-DO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "original_sys_path = sys.path.copy()\n",
        "\n",
        "# sys.path.append('/content/bachlor_backup/src/autoencoder')\n",
        "# import train as autoencoder_train\n",
        "\n",
        "sys.path.append('/content/bachlor_backup/src/segmentation/unet/')\n",
        "import train as unet_train\n",
        "\n",
        "# sys.path.append('/content/bachlor_backup/src/segmentation/segformer/')\n",
        "# import train as segformer_train\n",
        "\n",
        "# sys.path.append('/content/bachlor_backup/src/classification/convnext')\n",
        "# import train as convnext_train\n",
        "\n",
        "# sys.path.append('/content/bachlor_backup/src/classification/efficienet')\n",
        "# import train as efficienet_train\n"
      ],
      "metadata": {
        "id": "zeC4Tv5b60yi"
      },
      "id": "zeC4Tv5b60yi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet_train.main()"
      ],
      "metadata": {
        "id": "-SpXut3SaM64"
      },
      "id": "-SpXut3SaM64",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZlmPIjWNCHdo"
      },
      "id": "ZlmPIjWNCHdo",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}