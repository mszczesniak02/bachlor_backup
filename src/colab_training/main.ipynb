{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ceb493c",
      "metadata": {
        "id": "8ceb493c"
      },
      "outputs": [],
      "source": [
        "!pip install -q segmentation-models-pytorch\n",
        "!git clone -q https://github.com/mszczesniak02/bachlor_backup.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1e8iUa45OsATWGrFJOVfE3x9-YZrWTQXG -O dataset.tar.gz\n",
        "!mkdir /content/datasets\n",
        "!tar -I pigz -xf /content/dataset.tar.gz -C /content/datasets/\n"
      ],
      "metadata": {
        "id": "OBsqR75Rrxd6"
      },
      "id": "OBsqR75Rrxd6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06ee7de0",
      "metadata": {
        "id": "06ee7de0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from google.colab import drive\n",
        "import glob\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e17e7092",
      "metadata": {
        "id": "e17e7092"
      },
      "outputs": [],
      "source": [
        "def make_dirs():\n",
        "    # make dirs for models & logs\n",
        "    dirs = [\n",
        "        \"/content/models\",\n",
        "\n",
        "        \"/content/models/segmentation\",\n",
        "        \"/content/models/classification\",\n",
        "        \"/content/models/autoencoder\",\n",
        "\n",
        "        \"/content/models/segmentation/unet\",\n",
        "        \"/content/models/segmentation/segformer\",\n",
        "        \"/content/models/classification/efficienet\",\n",
        "        \"/content/models/classification/convnext\",\n",
        "\n",
        "        \"/content/models_log\",\n",
        "\n",
        "        \"/content/models_log/segmentation\",\n",
        "        \"/content/models_log/segmentation/unet\",\n",
        "        \"/content/models_log/segmentation/segformer\",\n",
        "\n",
        "        \"/content/models_log/classification\",\n",
        "        \"/content/models_log/classification/efficienet\",\n",
        "        \"/content/models_log/classification/convnext\",\n",
        "        \"/content/models_log/autoencoder\",\n",
        "    ]\n",
        "    for dir in dirs:\n",
        "        os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "def mount_drive():\n",
        "\n",
        "    drive.mount('/content/drive')\n",
        "    source = '/content/drive/MyDrive/datasets/multi'  # Na Drive\n",
        "    destination = '/content/datasets/multi'            # Link lokalny\n",
        "\n",
        "    os.makedirs('/content/datasets', exist_ok=True)\n",
        "\n",
        "    if os.path.exists(destination):\n",
        "        if os.path.islink(destination):\n",
        "            os.unlink(destination)\n",
        "        else:\n",
        "            shutil.rmtree(destination)\n",
        "\n",
        "    # os.symlink(source, destination)\n",
        "    print(f\"Copying dataset from {source} to {destination}...\")\n",
        "\n",
        "    # Count files for progress bar\n",
        "    total_files = sum([len(files) for r, d, files in os.walk(source)])\n",
        "\n",
        "    with tqdm(total=total_files, desc=\"Copying\", unit=\"file\") as pbar:\n",
        "        def copy_func(src, dst):\n",
        "            shutil.copy2(src, dst)\n",
        "            pbar.update(1)\n",
        "\n",
        "        shutil.copytree(source, destination, copy_function=copy_func)\n",
        "\n",
        "    print(f\"Dataset copied!\")\n",
        "    print(f\"  {destination} <- {source}\")\n",
        "\n",
        "def set_colab(path: str, on_colab: bool):\n",
        "    dir = Path(path)\n",
        "    result = list(dir.rglob(\"hparams.[pP][yY]\"))\n",
        "    for r in result:\n",
        "        with open(r, \"r+\") as f:\n",
        "            pos = f.tell()\n",
        "            line = f.readline()\n",
        "            if on_colab:\n",
        "                if line == \"ON_COLAB = False\\n\":\n",
        "                    f.seek(pos)\n",
        "                    f.write(\"ON_COLAB = True\\n\")\n",
        "            else:\n",
        "                if line == \"ON_COLAB = True\\n\":\n",
        "                    f.seek(pos)\n",
        "                    f.write(\"ON_COLAB = False\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41754732",
      "metadata": {
        "id": "41754732"
      },
      "outputs": [],
      "source": [
        "make_dirs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06ca01e3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06ca01e3",
        "outputId": "6ba25975-7a76-48f6-a7d8-a43fdc7b7135"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Copying dataset from /content/drive/MyDrive/datasets/multi to /content/datasets/multi...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying: 100%|██████████| 26200/26200 [10:09<00:00, 42.98file/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset copied!\n",
            "  /content/datasets/multi <- /content/drive/MyDrive/datasets/multi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "mount_drive()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c50e9af",
      "metadata": {
        "id": "4c50e9af"
      },
      "outputs": [],
      "source": [
        "set_colab(\"/content/bachlor_backup/src\", True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e875da4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e875da4",
        "outputId": "0780b6d8-b789-49eb-96f0-cbac1841fc46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ON_COLAB = True\n",
            "ON_COLAB = True\n",
            "ON_COLAB = True\n",
            "cat: bachlor_backup/src/dim_translator/hparams.py: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!cat bachlor_backup/src/segmentation/common/hparams.py | head -1\n",
        "!cat bachlor_backup/src/classification/common/hparams.py | head -1\n",
        "!cat bachlor_backup/src/autoencoder/hparams.py | head -1\n",
        "!cat bachlor_backup/src/dim_translator/hparams.py | head -1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rd bachlor_backup/"
      ],
      "metadata": {
        "id": "9GBZdPiCXImc"
      },
      "id": "9GBZdPiCXImc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd bachlor_backup/src/autoencoder && python train.py"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-WcQQDSWU-DO"
      },
      "id": "-WcQQDSWU-DO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "original_sys_path = sys.path.copy()\n",
        "\n",
        "sys.path.append('/content/bachlor_backup/src/autoencoder')\n",
        "import train as autoencoder_train\n",
        "\n",
        "sys.path.append('/content/bachlor_backup/src/segmentation/unet/')\n",
        "import train as unet_train\n",
        "\n",
        "sys.path.append('/content/bachlor_backup/src/segmentation/segformer/')\n",
        "import train as segformer_train\n",
        "\n",
        "sys.path.append('/content/bachlor_backup/src/classification/convnext')\n",
        "import train as convnext_train\n",
        "\n",
        "sys.path.append('/content/bachlor_backup/src/classification/efficienet')\n",
        "import train as efficienet_train\n"
      ],
      "metadata": {
        "id": "1iST6XJ7khyT"
      },
      "id": "1iST6XJ7khyT",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}